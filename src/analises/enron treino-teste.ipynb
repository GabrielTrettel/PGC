{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv, nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.svm.SVC\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "      <th>file_index</th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p</td>\n",
       "      <td>sent_mail</td>\n",
       "      <td>1.0</td>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>\\nHere is our forecast\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p</td>\n",
       "      <td>sent_mail</td>\n",
       "      <td>10.0</td>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>\\nTraveling to have a business meeting takes t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p</td>\n",
       "      <td>sent_mail</td>\n",
       "      <td>100.0</td>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>\\ntest successful.  way to go!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p</td>\n",
       "      <td>sent_mail</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>\\nRandy,\\n\\n Can you send me a schedule of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p</td>\n",
       "      <td>sent_mail</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>\\nLet's shoot for Tuesday at 11:45.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30104</th>\n",
       "      <td>whalley-l</td>\n",
       "      <td>sent_mail</td>\n",
       "      <td>95.0</td>\n",
       "      <td>whalley-l/_sent_mail/95.</td>\n",
       "      <td>\\nBrad,\\n\\nGreg asked that I drop you a line t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30105</th>\n",
       "      <td>whalley-l</td>\n",
       "      <td>sent_mail</td>\n",
       "      <td>96.0</td>\n",
       "      <td>whalley-l/_sent_mail/96.</td>\n",
       "      <td>\\nReceived test message.\\n\\n\\n   \\n\\tEnron Nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30106</th>\n",
       "      <td>whalley-l</td>\n",
       "      <td>sent_mail</td>\n",
       "      <td>97.0</td>\n",
       "      <td>whalley-l/_sent_mail/97.</td>\n",
       "      <td>\\ni will try to call and talk you thru this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30107</th>\n",
       "      <td>whalley-l</td>\n",
       "      <td>sent_mail</td>\n",
       "      <td>98.0</td>\n",
       "      <td>whalley-l/_sent_mail/98.</td>\n",
       "      <td>\\nAllan,\\n\\nPlease remove Greg Whalley from th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30108</th>\n",
       "      <td>whalley-l</td>\n",
       "      <td>sent_mail</td>\n",
       "      <td>99.0</td>\n",
       "      <td>whalley-l/_sent_mail/99.</td>\n",
       "      <td>\\nJohn,\\n\\nPlease remove Greg Whalley from thi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26145 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          author   category  file_index                      file  \\\n",
       "0        allen-p  sent_mail         1.0     allen-p/_sent_mail/1.   \n",
       "1        allen-p  sent_mail        10.0    allen-p/_sent_mail/10.   \n",
       "2        allen-p  sent_mail       100.0   allen-p/_sent_mail/100.   \n",
       "3        allen-p  sent_mail      1000.0  allen-p/_sent_mail/1000.   \n",
       "4        allen-p  sent_mail      1001.0  allen-p/_sent_mail/1001.   \n",
       "...          ...        ...         ...                       ...   \n",
       "30104  whalley-l  sent_mail        95.0  whalley-l/_sent_mail/95.   \n",
       "30105  whalley-l  sent_mail        96.0  whalley-l/_sent_mail/96.   \n",
       "30106  whalley-l  sent_mail        97.0  whalley-l/_sent_mail/97.   \n",
       "30107  whalley-l  sent_mail        98.0  whalley-l/_sent_mail/98.   \n",
       "30108  whalley-l  sent_mail        99.0  whalley-l/_sent_mail/99.   \n",
       "\n",
       "                                                 message  \n",
       "0                            \\nHere is our forecast\\n\\n   \n",
       "1      \\nTraveling to have a business meeting takes t...  \n",
       "2                       \\ntest successful.  way to go!!!  \n",
       "3      \\nRandy,\\n\\n Can you send me a schedule of the...  \n",
       "4                  \\nLet's shoot for Tuesday at 11:45.    \n",
       "...                                                  ...  \n",
       "30104  \\nBrad,\\n\\nGreg asked that I drop you a line t...  \n",
       "30105  \\nReceived test message.\\n\\n\\n   \\n\\tEnron Nor...  \n",
       "30106        \\ni will try to call and talk you thru this  \n",
       "30107  \\nAllan,\\n\\nPlease remove Greg Whalley from th...  \n",
       "30108  \\nJohn,\\n\\nPlease remove Greg Whalley from thi...  \n",
       "\n",
       "[26145 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron = pd.read_csv(\"../../../datasets/emails-filtered.csv\",\n",
    "                    sep=\",\",\n",
    "                    quoting=csv.QUOTE_ALL)\n",
    "\n",
    "\n",
    "enron = enron.dropna(axis=\"index\", subset=[\"message\"])\n",
    "enron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré processamento\n",
    " - remover quebra de linhas ao inicio (já que ela costuma aparecer por conta da remoção do header)\n",
    " - trocar o nome do autor por numeros sequenciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(email_txt: str):\n",
    "    if isinstance(email_txt, float):\n",
    "        print(email_txt)\n",
    "        return email_txt\n",
    "    \n",
    "    if len(email_txt) < 2:\n",
    "        return email_txt\n",
    "\n",
    "    return email_txt if email_txt[:1] != \"\\n\" else email_txt[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "enron[\"message\"] = enron[\"message\"].apply(preProcessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "enron = enron[[\"message\", \"author\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_names = list(enron[\"author\"].unique())\n",
    "author_name_to_idx = dict(zip(authors_names, range(0, len(authors_names))))\n",
    "\n",
    "enron.author = enron.author.apply(lambda x: author_name_to_idx[x])\n",
    "\n",
    "enron.to_csv(path_or_buf=\"../../../datasets/enron_interest.csv\", index=False, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  3,  4, 14, 19, 21, 24, 34, 38, 43, 45, 48, 59, 60, 63, 70]),\n",
       "                                                  message  author\n",
       " 602    saw a lot of the bulls sell summer against len...       1\n",
       " 603    amazing how with cash futures at $1 and the ba...       1\n",
       " 604                   We both thank you\\n\\n\\n   \\n\\t\\n\\t       1\n",
       " 605    So, what is it?   And by the way, don't start ...       1\n",
       " 606    sure, stop by and we'll arrange a place to mee...       1\n",
       " ...                                                  ...     ...\n",
       " 29204  As you might have noticed, there was no file a...      70\n",
       " 29205  The graphs I've set on your desks are the prod...      70\n",
       " 29206  Matt Motley and Mike Swerzbin both said this t...      70\n",
       " 29207  That is actually the report I'm having problem...      70\n",
       " 29208  The STCA desk will be short 75 MW on peak at N...      70\n",
       " \n",
       " [19090 rows x 2 columns])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_names = enron.author.unique()\n",
    "df = enron\n",
    "\n",
    "botton = 500\n",
    "top = 1_000_000\n",
    "\n",
    "for name in unique_names:\n",
    "    emails_qtd = len(df[df.author == name])\n",
    "    if emails_qtd > top or emails_qtd < botton:\n",
    "        df = df[df.author != name]\n",
    "\n",
    "df.author.unique(), df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separação treino-teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do treino: 5307\n",
      "Tamanho do teste: 1327\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(enron, test_size=0.2)\n",
    "\n",
    "print(f\"Tamanho do treino: {len(train)}\\nTamanho do teste: {len(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração de características\n",
    "\n",
    "- Neste exemplo, bag of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_re = r'\\b\\w+\\b'\n",
    "vectorizer = CountVectorizer(ngram_range=(2,2), token_pattern=word_re)\n",
    "\n",
    "train_BOW = vectorizer.fit_transform(train['message'])\n",
    "test_BOW  = vectorizer.fit_transform(test['message'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['author']\n",
    "y_test = test['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(3,3), token_pattern=word_re).fit(train['message'])\n",
    "train_tfidfv = vectorizer.transform(train['message'])\n",
    "test_tfidfv = vectorizer.transform(test['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer()  (20916, 936090) (5229, 936090)\n"
     ]
    }
   ],
   "source": [
    "print(\"TfidfVectorizer() \", train_tfidfv.shape, test_tfidfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(chi2, k=1000).fit(train_tfidfv, y_train)\n",
    "x_train = selector.transform(train_tfidfv)\n",
    "x_test  = selector.transform(test_tfidfv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45, 45, 45, ..., 70, 45, 45])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf.predict(x_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17804551539491298"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "confusion_matrix(pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          19       0.01      1.00      0.02         1\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.16      0.80      0.26        45\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.01      1.00      0.02         1\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.16      0.89      0.27         9\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         0\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.29      0.01         7\n",
      "          35       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         0\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         0\n",
      "          45       1.00      0.16      0.27      5073\n",
      "          46       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       0.00      0.00      0.00         0\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.00      0.00      0.00         0\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       0.01      0.50      0.01         2\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.36      1.00      0.53        91\n",
      "          71       0.00      0.00      0.00         0\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         0\n",
      "          74       0.00      0.00      0.00         0\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.18      5229\n",
      "   macro avg       0.02      0.08      0.02      5229\n",
      "weighted avg       0.98      0.18      0.27      5229\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(df, \n",
    "             test_size: int = 0.2,\n",
    "             x:str = \"message\",\n",
    "             y:str = \"author\",\n",
    "             word_re: str = r'\\b\\w+\\b',\n",
    "             vectorizer = TfidfVectorizer,\n",
    "             selector = SelectKBest,\n",
    "             K:int = 1000,\n",
    "             ngram_range: tuple = (2,2),\n",
    "             classifier = MultinomialNB):\n",
    "    \n",
    "    \n",
    "    train, test = train_test_split(df, test_size=test_size)\n",
    "    print(f\"Tamanho do treino: {len(train)}\\nTamanho do teste: {len(test)}\")\n",
    "    \n",
    "    print(\"Extração de características\")\n",
    "    train_X = train[x]\n",
    "    train_Y = train[y]\n",
    "    test_X  = test[x]\n",
    "    test_Y  = test[y]\n",
    "    \n",
    "    \n",
    "    vectorizer_f = vectorizer(ngram_range=ngram_range, token_pattern=word_re).fit(train_X)\n",
    "    \n",
    "    train_X = vectorizer_f.transform(train_X)\n",
    "    test_X = vectorizer_f.transform(test_X)  \n",
    "    print(\"Shape: \", train_X.shape, test_X.shape)\n",
    "    \n",
    "    print(\"Seleção de características\")\n",
    "    selector_f = selector(chi2, k=K).fit(train_X, train_Y)\n",
    "    train_X = selector_f.transform(train_X)\n",
    "    test_X  = selector_f.transform(test_X)\n",
    "    \n",
    "    print(\"Classificação\")\n",
    "    clf = classifier()\n",
    "    clf.fit(train_X, train_Y)\n",
    "    pred = clf.predict(test_X)\n",
    "    print(f\"score {clf.score(test_X, test_Y)}\")\n",
    "    \n",
    "    \n",
    "    return pred, test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do treino: 15272\n",
      "Tamanho do teste: 3818\n",
      "Extração de características\n",
      "Shape:  (15272, 343844) (3818, 343844)\n",
      "Seleção de características\n",
      "Classificação\n",
      "score 0.46097433211105293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([45, 45, 34, ..., 34, 45, 45])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred, test_Y = pipeline(df, K=6000)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.08      1.00      0.15        11\n",
      "           3       0.40      0.97      0.57       108\n",
      "           4       0.10      1.00      0.18        23\n",
      "          14       0.12      1.00      0.22        18\n",
      "          19       0.29      1.00      0.46        41\n",
      "          21       0.38      0.88      0.53        91\n",
      "          24       0.29      0.95      0.44        87\n",
      "          34       0.74      0.83      0.78       423\n",
      "          38       0.00      0.00      0.00         0\n",
      "          43       0.01      1.00      0.02         1\n",
      "          45       0.99      0.29      0.45      2758\n",
      "          48       0.02      1.00      0.05         4\n",
      "          59       0.14      0.95      0.24        21\n",
      "          60       0.28      0.96      0.43        48\n",
      "          63       0.02      1.00      0.04         4\n",
      "          70       0.69      0.99      0.82       180\n",
      "\n",
      "    accuracy                           0.46      3818\n",
      "   macro avg       0.28      0.86      0.33      3818\n",
      "weighted avg       0.87      0.46      0.50      3818\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred, test_Y))"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
